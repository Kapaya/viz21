
@article{bostock2011,
  title = {{{D}}³ {{Data}}-{{Driven Documents}}},
  author = {Bostock, Michael and Ogievetsky, Vadim and Heer, Jeffrey},
  date = {2011-12},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {17},
  pages = {2301--2309},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2011.185},
  abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  file = {/Users/kapayakatongo/Zotero/storage/7FZ2RXLR/Bostock et al. - 2011 - D³ Data-Driven Documents.pdf;/Users/kapayakatongo/Zotero/storage/GATVKRPM/6064996.html},
  keywords = {2D graphics.,Cascading style sheets,Data visualization,Debugging,Image color analysis,Information analysis,Information visualization,toolkits,user interfaces},
  number = {12}
}

@article{chan2008,
  title = {Vispedia: {{Interactive Visual Exploration}} of {{Wikipedia Data}} via {{Search}}-{{Based Integration}}},
  shorttitle = {Vispedia},
  author = {Chan, Bryan and Wu, Leslie and Talbot, Justin and Cammarano, Mike and Hanrahan, Pat},
  date = {2008-11},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {14},
  pages = {1213--1220},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2008.178},
  abstract = {Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia's hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the "long tail" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  file = {/Users/kapayakatongo/Zotero/storage/FCGHYPWK/Chan et al. - 2008 - Vispedia Interactive Visual Exploration of Wikipe.pdf;/Users/kapayakatongo/Zotero/storage/WBEAPTCD/4658132.html},
  keywords = {Cleaning,Collaboration,Collaborative software,Costs,data integration,Data mining,Data visualization,Eyes,Index Terms—,information visualization,Iterative algorithms,search interface,semantic web,Semantic Web,Wikipedia},
  number = {6}
}

@inproceedings{chasins2018,
  title = {Rousillon: {{Scraping Distributed Hierarchical Web Data}}},
  shorttitle = {Rousillon},
  booktitle = {Proceedings of the 31st {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Chasins, Sarah E. and Mueller, Maria and Bodik, Rastislav},
  date = {2018-10-11},
  pages = {963--975},
  publisher = {{ACM}},
  location = {{Berlin Germany}},
  doi = {10.1145/3242587.3242661},
  url = {https://dl.acm.org/doi/10.1145/3242587.3242661},
  urldate = {2021-05-19},
  abstract = {Programming by Demonstration (PBD) promises to enable data scientists to collect web data. However, in formative interviews with social scientists, we learned that current PBD tools are insufficient for many real-world web scraping tasks. The missing piece is the capability to collect hierarchicallystructured data from across many different webpages. We present Rousillon, a programming system for writing complex web automation scripts by demonstration. Users demonstrate how to collect the first row of a ‘universal table’ view of a hierarchical dataset to teach Rousillon how to collect all rows. To offer this new demonstration model, we developed novel relation selection and generalization algorithms. In a withinsubject user study on 15 computer scientists, users can write hierarchical web scrapers 8 times more quickly with Rousillon than with traditional programming.},
  eventtitle = {{{UIST}} '18: {{The}} 31st {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  file = {/Users/kapayakatongo/Zotero/storage/FQ6RM3TA/Chasins et al. - 2018 - Rousillon Scraping Distributed Hierarchical Web D.pdf},
  isbn = {978-1-4503-5948-1},
  langid = {english}
}

@inproceedings{huynh2006,
  title = {Enabling Web Browsers to Augment Web Sites' Filtering and Sorting Functionalities},
  booktitle = {Proceedings of the 19th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology - {{UIST}} '06},
  author = {Huynh, David F. and Miller, Robert C. and Karger, David R.},
  date = {2006},
  pages = {125},
  publisher = {{ACM Press}},
  location = {{Montreux, Switzerland}},
  doi = {10.1145/1166253.1166274},
  url = {http://dl.acm.org/citation.cfm?doid=1166253.1166274},
  urldate = {2021-05-19},
  abstract = {Existing augmentations of web pages are mostly small cosmetic changes (e.g., removing ads) and minor addition of third-party content (e.g., product prices from competing sites). None leverages the structured data presented in web pages. This paper describes Sifter, a web browser extension that can augment a well-structured web site with advanced filtering and sorting functionality. These added features work inside the site’s own pages, preserving the site’s presentational style and the user’s context. Sifter contains an algorithm that scrapes structured data out of well-structured web pages while usually requiring no user intervention. We tested Sifter on real web sites and real users and found that people could use Sifter to perform sophisticated queries and high-level analyses on sizable data collections on the Web. We propose that web sites can be similarly augmented with other sophisticated data-centric functionality, giving users new benefits over the existing Web.},
  eventtitle = {The 19th Annual {{ACM}} Symposium},
  file = {/Users/kapayakatongo/Zotero/storage/793J57J6/Huynh et al. - 2006 - Enabling web browsers to augment web sites' filter.pdf},
  isbn = {978-1-59593-313-3},
  langid = {english}
}

@article{kushmerick2000,
  title = {Wrapper Induction: {{Efficiency}} and Expressiveness},
  shorttitle = {Wrapper Induction},
  author = {Kushmerick, Nicholas},
  date = {2000-04},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {118},
  pages = {15--68},
  issn = {00043702},
  doi = {10.1016/S0004-3702(99)00100-9},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0004370299001009},
  urldate = {2021-05-19},
  abstract = {The Internet presents numerous sources of useful information—telephone directories, product catalogs, stock quotes, event listings, etc. Recently, many systems have been built that automatically gather and manipulate such information on a user’s behalf. However, these resources are usually formatted for use by people (e.g., the relevant content is embedded in HTML pages), so extracting their content is difficult. Most systems use customized wrapper procedures to perform this extraction task. Unfortunately, writing wrappers is tedious and error-prone. As an alternative, we advocate wrapper induction, a technique for automatically constructing wrappers. In this article, we describe six wrapper classes, and use a combination of empirical and analytical techniques to evaluate the computational tradeoffs among them. We first consider expressiveness: how well the classes can handle actual Internet resources, and the extent to which wrappers in one class can mimic those in another. We then turn to efficiency: we measure the number of examples and time required to learn wrappers in each class, and we compare these results to PAC models of our task and asymptotic complexity analyses of our algorithms. Summarizing our results, we find that most of our wrapper classes are reasonably useful (70\% of surveyed sites can be handled in total), yet can rapidly learned (learning usually requires just a handful of examples and a fraction of a CPU second per example). © 2000 Elsevier Science B.V. All rights reserved.},
  file = {/Users/kapayakatongo/Zotero/storage/NNUSZF6V/Kushmerick - 2000 - Wrapper induction Efficiency and expressiveness.pdf},
  langid = {english},
  number = {1-2}
}

@inproceedings{le2014,
  title = {{{FlashExtract}}: A Framework for Data Extraction by Examples},
  shorttitle = {{{FlashExtract}}},
  booktitle = {Proceedings of the 35th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Le, Vu and Gulwani, Sumit},
  date = {2014-06-09},
  pages = {542--553},
  publisher = {{ACM}},
  location = {{Edinburgh United Kingdom}},
  doi = {10.1145/2594291.2594333},
  url = {https://dl.acm.org/doi/10.1145/2594291.2594333},
  urldate = {2021-05-19},
  abstract = {Various document types that combine model and view (e.g., text files, webpages, spreadsheets) make it easy to organize (possibly hierarchical) data, but make it difficult to extract raw data for any further manipulation or querying. We present a general framework FlashExtract to extract relevant data from semi-structured documents using examples. It includes: (a) an interaction model that allows end-users to give examples to extract various fields and to relate them in a hierarchical organization using structure and sequence constructs. (b) an inductive synthesis algorithm to synthesize the intended program from few examples in any underlying domainspecific language for data extraction that has been built using our specified algebra of few core operators (map, filter, merge, and pair). We describe instantiation of our framework to three different domains: text files, webpages, and spreadsheets. On our benchmark comprising 75 documents, FlashExtract is able to extract intended data using an average of 2.36 examples in 0.84 seconds per field.},
  eventtitle = {{{PLDI}} '14: {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  file = {/Users/kapayakatongo/Zotero/storage/JCZWLWQL/Le and Gulwani - 2014 - FlashExtract a framework for data extraction by e.pdf},
  isbn = {978-1-4503-2784-8},
  langid = {english}
}

@inproceedings{lin2009,
  title = {End-User Programming of Mashups with Vegemite},
  booktitle = {Proceedings of the 14th International Conference on {{Intelligent}} User Interfaces},
  author = {Lin, James and Wong, Jeffrey and Nichols, Jeffrey and Cypher, Allen and Lau, Tessa A.},
  date = {2009-02-08},
  pages = {97--106},
  publisher = {{ACM}},
  location = {{Sanibel Island Florida USA}},
  doi = {10.1145/1502650.1502667},
  url = {https://dl.acm.org/doi/10.1145/1502650.1502667},
  urldate = {2021-05-19},
  abstract = {Mashups are an increasingly popular way to integrate data from multiple web sites to fit a particular need, but it often requires substantial technical expertise to create them. To lower the barrier for creating mashups, we have extended the CoScripter web automation tool with a spreadsheet-like environment called Vegemite. Our system uses directmanipulation and programming-by-demonstration techniques to automatically populate tables with information collected from various web sites. A particular strength of our approach is its ability to augment a data set with new values computed by a web site, such as determining the driving distance from a particular location to each of the addresses in a data set. An informal user study suggests that Vegemite may enable a wider class of users to address their information needs.},
  eventtitle = {{{IUI09}}: 14th {{International Conference}} on {{Intelligent User Interfaces}}},
  file = {/Users/kapayakatongo/Zotero/storage/YVSDDCA7/Lin et al. - 2009 - End-user programming of mashups with vegemite.pdf},
  isbn = {978-1-60558-168-2},
  langid = {english}
}

@inproceedings{litt2020,
  title = {End-User Software Customization by Direct Manipulation of Tabular Data},
  booktitle = {Proceedings of the 2020 {{ACM SIGPLAN International Symposium}} on {{New Ideas}}, {{New Paradigms}}, and {{Reflections}} on {{Programming}} and {{Software}}},
  author = {Litt, Geoffrey and Jackson, Daniel and Millis, Tyler and Quaye, Jessica},
  date = {2020-11-18},
  pages = {18--33},
  publisher = {{ACM}},
  location = {{Virtual USA}},
  doi = {10.1145/3426428.3426914},
  url = {https://dl.acm.org/doi/10.1145/3426428.3426914},
  urldate = {2021-06-18},
  abstract = {Customizing software should be as easy as using it. Unfortunately, most customization methods require users to abruptly shift from using a graphical interface to writing scripts in a programming language.},
  eventtitle = {{{SPLASH}} '20: {{Conference}} on {{Systems}}, {{Programming}}, {{Languages}}, and {{Applications}}, {{Software}} for {{Humanity}}},
  file = {/Users/kapayakatongo/Zotero/storage/7EMEB8XY/Litt et al. - 2020 - End-user software customization by direct manipula.pdf},
  isbn = {978-1-4503-8178-9},
  langid = {english}
}

@article{satyanarayan2016,
  title = {Reactive {{Vega}}: {{A Streaming Dataflow Architecture}} for {{Declarative Interactive Visualization}}},
  shorttitle = {Reactive {{Vega}}},
  author = {Satyanarayan, Arvind and Russell, Ryan and Hoffswell, Jane and Heer, Jeffrey},
  date = {2016-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {22},
  pages = {659--668},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2015.2467091},
  abstract = {We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  file = {/Users/kapayakatongo/Zotero/storage/X37JXXY7/Satyanarayan et al. - 2016 - Reactive Vega A Streaming Dataflow Architecture f.pdf;/Users/kapayakatongo/Zotero/storage/5MUZM7QU/7192704.html},
  keywords = {Computer architecture,Data models,Data visualization,declarative specification,Encoding,Indexes,Information visualization,interaction,optimization,Runtime,streaming data,systems,toolkits,Visualization},
  number = {1}
}

@article{satyanarayan2017,
  title = {Vega-{{Lite}}: {{A Grammar}} of {{Interactive Graphics}}},
  shorttitle = {Vega-{{Lite}}},
  author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
  date = {2017-01},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  volume = {23},
  pages = {341--350},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2016.2599030},
  abstract = {We present Vega-Lite, a high-level grammar that enables rapid specification of interactive data visualizations. Vega-Lite combines a traditional grammar of graphics, providing visual encoding rules and a composition algebra for layered and multi-view displays, with a novel grammar of interaction. Users specify interactive semantics by composing selections. In Vega-Lite, a selection is an abstraction that defines input event processing, points of interest, and a predicate function for inclusion testing. Selections parameterize visual encodings by serving as input data, defining scale extents, or by driving conditional logic. The Vega-Lite compiler automatically synthesizes requisite data flow and event handling logic, which users can override for further customization. In contrast to existing reactive specifications, Vega-Lite selections decompose an interaction design into concise, enumerable semantic units. We evaluate Vega-Lite through a range of examples, demonstrating succinct specification of both customized interaction methods and common techniques such as panning, zooming, and linked selection.},
  eventtitle = {{{IEEE Transactions}} on {{Visualization}} and {{Computer Graphics}}},
  file = {/Users/kapayakatongo/Zotero/storage/V5T69MGW/Satyanarayan et al. - 2017 - Vega-Lite A Grammar of Interactive Graphics.pdf;/Users/kapayakatongo/Zotero/storage/DYMUNRYH/7539624.html},
  keywords = {Brushes,Data visualization,declarative specification,Encoding,Grammar,Information visualization,interaction,systems,toolkits,Transforms,Visualization},
  number = {1}
}

@inproceedings{toomim2009,
  title = {Attaching {{UI}} Enhancements to Websites with End Users},
  booktitle = {Proceedings of the 27th International Conference on {{Human}} Factors in Computing Systems - {{CHI}} 09},
  author = {Toomim, Michael and Drucker, Steven M. and Dontcheva, Mira and Rahimi, Ali and Thomson, Blake and Landay, James A.},
  date = {2009},
  pages = {1859},
  publisher = {{ACM Press}},
  location = {{Boston, MA, USA}},
  doi = {10.1145/1518701.1518987},
  url = {http://dl.acm.org/citation.cfm?doid=1518701.1518987},
  urldate = {2021-05-19},
  abstract = {We present reform, a step toward write-once apply-anywhere user interface enhancements. The reform system envisions roles for both programmers and end users in enhancing existing websites to support new goals. First, a programmer authors a traditional mashup or browser extension, but they do not write a web scraper. Instead they use reform, which allows novice end users to attach the enhancement to their favorite sites with a scraping by-example interface. reform makes enhancements easier to program while also carrying the benefit that end users can apply the enhancements to any number of new websites. We present reform’s architecture, user interface, interactive by-example extraction algorithm for novices, and evaluation, along with five example reform enabled enhancements.},
  eventtitle = {The {{SIGCHI Conference}}},
  file = {/Users/kapayakatongo/Zotero/storage/NNQ6IMUC/Toomim et al. - 2009 - Attaching UI enhancements to websites with end use.pdf},
  isbn = {978-1-60558-246-7},
  langid = {english}
}

@inproceedings{wongsuphasawat2016,
  title = {Towards a General-Purpose Query Language for Visualization Recommendation},
  booktitle = {Proceedings of the {{Workshop}} on {{Human}}-{{In}}-the-{{Loop Data Analytics}} - {{HILDA}} '16},
  author = {Wongsuphasawat, Kanit and Moritz, Dominik and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
  date = {2016},
  pages = {1--6},
  publisher = {{ACM Press}},
  location = {{San Francisco, California}},
  doi = {10.1145/2939502.2939506},
  url = {http://dl.acm.org/citation.cfm?doid=2939502.2939506},
  urldate = {2021-06-18},
  abstract = {Creating effective visualizations requires domain familiarity as well as design and analysis expertise, and may impose a tedious specification process. To address these difficulties, many visualization tools complement manual specification with recommendations. However, designing interfaces, ranking metrics, and scalable recommender systems remain important research challenges. In this paper, we propose a common framework for facilitating the development of visualization recommender systems in the form of a specification language for querying over the space of visualizations. We present the preliminary design of CompassQL, which defines (1) a partial specification that describes enumeration constraints, and (2) methods for choosing, ranking, and grouping recommended visualizations. To demonstrate the expressivity of the language, we describe existing recommender systems in terms of CompassQL queries. Finally, we discuss the prospective benefits of a common language for future visualization recommender systems.},
  eventtitle = {The {{Workshop}}},
  file = {/Users/kapayakatongo/Zotero/storage/GAA54FAH/Wongsuphasawat et al. - 2016 - Towards a general-purpose query language for visua.pdf},
  isbn = {978-1-4503-4207-0},
  langid = {english}
}

@article{wongsuphasawat2016a,
  title = {Voyager: {{Exploratory Analysis}} via {{Faceted Browsing}} of {{Visualization Recommendations}}},
  shorttitle = {Voyager},
  author = {Wongsuphasawat, Kanit and Moritz, Dominik and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
  date = {2016-01-31},
  journaltitle = {IEEE Transactions on Visualization and Computer Graphics},
  shortjournal = {IEEE Trans. Visual. Comput. Graphics},
  volume = {22},
  pages = {649--658},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2015.2467191},
  url = {http://ieeexplore.ieee.org/document/7192728/},
  urldate = {2021-06-18},
  abstract = {General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager’s architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering.},
  file = {/Users/kapayakatongo/Zotero/storage/YN4U9V95/Wongsuphasawat et al. - 2016 - Voyager Exploratory Analysis via Faceted Browsing.pdf},
  langid = {english},
  number = {1}
}

@inproceedings{wongsuphasawat2017,
  title = {Voyager 2: {{Augmenting Visual Analysis}} with {{Partial View Specifications}}},
  shorttitle = {Voyager 2},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wongsuphasawat, Kanit and Qu, Zening and Moritz, Dominik and Chang, Riley and Ouk, Felix and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
  date = {2017-05-02},
  pages = {2648--2659},
  publisher = {{ACM}},
  location = {{Denver Colorado USA}},
  doi = {10.1145/3025453.3025768},
  url = {https://dl.acm.org/doi/10.1145/3025453.3025768},
  urldate = {2021-05-19},
  abstract = {Visual data analysis involves both open-ended and focused exploration. Manual chart specification tools support question answering, but are often tedious for early-stage exploration where systematic data coverage is needed. Visualization recommenders can encourage broad coverage, but irrelevant suggestions may distract users once they commit to specific questions. We present Voyager 2, a mixed-initiative system that blends manual and automated chart specification to help analysts engage in both open-ended exploration and targeted question answering. We contribute two partial specification interfaces: wildcards let users specify multiple charts in parallel, while related views suggest visualizations relevant to the currently specified chart. We present our interface design and applications of the CompassQL visualization query language to enable these interfaces. In a controlled study we find that Voyager 2 leads to increased data field coverage compared to a traditional specification tool, while still allowing analysts to flexibly drill-down and answer specific questions.},
  eventtitle = {{{CHI}} '17: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  file = {/Users/kapayakatongo/Zotero/storage/UT3SSRIP/Wongsuphasawat et al. - 2017 - Voyager 2 Augmenting Visual Analysis with Partial.pdf},
  isbn = {978-1-4503-4655-9},
  langid = {english}
}

@inproceedings{wongsuphasawat2017a,
  title = {Voyager 2: {{Augmenting Visual Analysis}} with {{Partial View Specifications}}},
  shorttitle = {Voyager 2},
  booktitle = {Proceedings of the 2017 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wongsuphasawat, Kanit and Qu, Zening and Moritz, Dominik and Chang, Riley and Ouk, Felix and Anand, Anushka and Mackinlay, Jock and Howe, Bill and Heer, Jeffrey},
  date = {2017-05-02},
  pages = {2648--2659},
  publisher = {{ACM}},
  location = {{Denver Colorado USA}},
  doi = {10.1145/3025453.3025768},
  url = {https://dl.acm.org/doi/10.1145/3025453.3025768},
  urldate = {2021-06-18},
  abstract = {Visual data analysis involves both open-ended and focused exploration. Manual chart specification tools support question answering, but are often tedious for early-stage exploration where systematic data coverage is needed. Visualization recommenders can encourage broad coverage, but irrelevant suggestions may distract users once they commit to specific questions. We present Voyager 2, a mixed-initiative system that blends manual and automated chart specification to help analysts engage in both open-ended exploration and targeted question answering. We contribute two partial specification interfaces: wildcards let users specify multiple charts in parallel, while related views suggest visualizations relevant to the currently specified chart. We present our interface design and applications of the CompassQL visualization query language to enable these interfaces. In a controlled study we find that Voyager 2 leads to increased data field coverage compared to a traditional specification tool, while still allowing analysts to flexibly drill-down and answer specific questions.},
  eventtitle = {{{CHI}} '17: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  file = {/Users/kapayakatongo/Zotero/storage/ZP7X4XKV/Wongsuphasawat et al. - 2017 - Voyager 2 Augmenting Visual Analysis with Partial.pdf},
  isbn = {978-1-4503-4655-9},
  langid = {english}
}

@inproceedings{zhang2017,
  title = {{{DS}}.Js: {{Turn Any Webpage}} into an {{Example}}-{{Centric Live Programming Environment}} for {{Learning Data Science}}},
  shorttitle = {{{DS}}.Js},
  booktitle = {Proceedings of the 30th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  author = {Zhang, Xiong and Guo, Philip J.},
  date = {2017-10-20},
  pages = {691--702},
  publisher = {{ACM}},
  location = {{Québec City QC Canada}},
  doi = {10.1145/3126594.3126663},
  url = {https://dl.acm.org/doi/10.1145/3126594.3126663},
  urldate = {2021-05-19},
  abstract = {Data science courses and tutorials have grown popular in recent years, yet they are still taught using production-grade programming tools (e.g., R, MATLAB, and Python IDEs) within desktop computing environments. Although powerful, these tools present high barriers to entry for novices, forcing them to grapple with the extrinsic complexities of software installation and configuration, data file management, data parsing, and Unix-like command-line interfaces. To lower the barrier for novices to get started with learning data science, we created DS.js, a bookmarklet that embeds a data science programming environment directly into any existing webpage. By transforming any webpage into an examplecentric IDE, DS.js eliminates the aforementioned complexities of desktop-based environments and turns the entire web into a rich substrate for learning data science. DS.js automatically parses HTML tables and CSV/TSV data sets on the target webpage, attaches code editors to each data set, provides a data table manipulation and visualization API designed for novices, and gives instructional scaffolding in the form of bidirectional previews of how the user’s code and data relate.},
  eventtitle = {{{UIST}} '17: {{The}} 30th {{Annual ACM Symposium}} on {{User Interface Software}} and {{Technology}}},
  file = {/Users/kapayakatongo/Zotero/storage/6Z4PSQJK/Zhang and Guo - 2017 - DS.js Turn Any Webpage into an Example-Centric Li.pdf},
  isbn = {978-1-4503-4981-9},
  langid = {english}
}

@online{zotero-276,
  title = {Beautiful {{Soup}}: {{We}} Called Him {{Tortoise}} Because He Taught Us.},
  url = {https://www.crummy.com/software/BeautifulSoup/},
  urldate = {2021-05-19},
  file = {/Users/kapayakatongo/Zotero/storage/FMF63SDG/BeautifulSoup.html}
}

@online{zotero-278,
  title = {{{SeleniumHQ Browser Automation}}},
  url = {https://www.selenium.dev/},
  urldate = {2021-05-19},
  file = {/Users/kapayakatongo/Zotero/storage/P6ZKLKVH/www.selenium.dev.html}
}

@online{zotero-280,
  title = {Scrapy | {{A Fast}} and {{Powerful Scraping}} and {{Web Crawling Framework}}},
  url = {https://scrapy.org/},
  urldate = {2021-05-19},
  file = {/Users/kapayakatongo/Zotero/storage/9L3BTQYD/scrapy.org.html}
}


